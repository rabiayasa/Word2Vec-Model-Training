## Training Word2Vec Model on English Wikidumps using Gensim
# Word2Vec Model
Words have semantically different meanings in daily use except lexicon meanings, and these semantic meanings depends on a text. In publication of "[Distributional Structure](https://www.tandfonline.com/doi/abs/10.1080/00437956.1954.11659520)", Harris [1] advocates that if two different words are elements of a group that has semantically close, these two words can be said to be similar.

Vector space model (in another saying distributional model) represents a system that creates word vectors from given corpus based on an unsupervised model. All words in a context represent with a dot and semantically related words tend to be close together in this space. This prediction-based method, developed by Mikolov at all [13], uses a neural network to perform a fruitful vector representation of unstructured text data.  




[1] Z. S. Harris, “Distributional structure,” Word, vol. 10, no. 2-3, pp. 146-162, 1954.
